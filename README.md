ğŸ§  GiriÅŸ: Derin Ã–ÄŸrenme Mimarilerine KapsamlÄ± Bir BakÄ±ÅŸ

Bu eÄŸitim serisi, derin Ã¶ÄŸrenmenin matematiksel temellerinden baÅŸlayarak, modern ve karmaÅŸÄ±k sinir aÄŸÄ± mimarilerine kadar uzanan geniÅŸ bir yelpazeyi ele almaktadÄ±r. Her bÃ¶lÃ¼mde, teorik bilginin pratik kodlamaya nasÄ±l dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼ÄŸÃ¼, endÃ¼stri standartlarÄ±ndaki en iyi pratikler (best practices) ile gÃ¶sterilmiÅŸtir. AmaÃ§, temel sÄ±nÄ±flandÄ±rma problemlerinden gÃ¶rÃ¼ntÃ¼ iÅŸleme ve zaman serisi tahminlemesine kadar farklÄ± alanlarda saÄŸlam ve uygulanabilir bir yetkinlik kazanmaktÄ±r.

ğŸ”§ Temel Sinir AÄŸlarÄ±: SÄ±fÄ±rdan Ä°nÅŸa (Foundational NNs: Building from Scratch)

Derin Ã¶ÄŸrenmenin temel dinamiklerini anlamak amacÄ±yla, NumPy kullanÄ±larak sÄ±fÄ±rdan basit bir yapay sinir aÄŸÄ± modeli inÅŸa edilmiÅŸtir. Bu bÃ¶lÃ¼m, kÃ¼tÃ¼phanelerin soyutladÄ±ÄŸÄ± katmanlarÄ±n arkasÄ±ndaki mekaniÄŸi anlamak iÃ§in kritik bir Ã¶neme sahiptir.

Teknik Detaylar:

Ä°leri YayÄ±lÄ±m (Forward Propagation) ve Geri YayÄ±lÄ±m (Backward Propagation) algoritmalarÄ±nÄ±n manuel implementasyonu.

Aktivasyon fonksiyonu olarak Sigmoid kullanÄ±mÄ±.

Logaritmik KayÄ±p (Log Loss) fonksiyonu ile model hatasÄ±nÄ±n hesaplanmasÄ±.

Kritik Ã‡Ä±karÄ±m:

FarklÄ± Ã¶ÄŸrenme oranlarÄ±nÄ±n (learning rate) modelin yakÄ±nsama hÄ±zÄ± ve performansÄ± Ã¼zerindeki etkisi analiz edilmiÅŸtir.

ğŸ“Š SÄ±nÄ±flandÄ±rma Problemleri ve Model Optimizasyonu

GerÃ§ek dÃ¼nya veri setleri (Pima Diyabet, Meme Kanseri) Ã¼zerinde ikili sÄ±nÄ±flandÄ±rma (binary classification) modelleri geliÅŸtirilmiÅŸ ve bu modellerin performansÄ±nÄ± iyileÅŸtirmeye yÃ¶nelik iki temel optimizasyon stratejisi incelenmiÅŸtir.

1. Manuel RegÃ¼larizasyon ile AÅŸÄ±rÄ± Ã–ÄŸrenme KontrolÃ¼ (Overfitting Control)

YÃ¼ksek kapasiteli modellerin ezberlemesini Ã¶nlemek amacÄ±yla, bilgiye dayalÄ± manuel optimizasyon teknikleri uygulanmÄ±ÅŸtÄ±r.

Uygulanan Teknikler:

L2 Regularization: AÄŸÄ±rlÄ±klarÄ±n bÃ¼yÃ¼mesini cezalandÄ±rarak model karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± sÄ±nÄ±rlar.

Batch Normalization: Katmanlar arasÄ±ndaki aktivasyonlarÄ± normalize ederek eÄŸitimi stabilize eder ve hÄ±zlandÄ±rÄ±r.

Dropout: EÄŸitim sÄ±rasÄ±nda nÃ¶ronlarÄ±n bir kÄ±smÄ±nÄ± rastgele kapatarak modelin genelleme yeteneÄŸini artÄ±rÄ±r.

Early Stopping: Validasyon kaybÄ± artmaya baÅŸladÄ±ÄŸÄ±nda eÄŸitimi durdurarak en iyi modelin korunmasÄ±nÄ± saÄŸlar.

2. Keras Tuner ile Otomatik Hiperparametre Optimizasyonu

En iyi model mimarisini bulma sÃ¼recini otomatize etmek iÃ§in Keras Tuner kÃ¼tÃ¼phanesi kullanÄ±lmÄ±ÅŸtÄ±r.

Teknik YaklaÅŸÄ±m:

GeniÅŸ Arama UzayÄ± (Search Space): Katman sayÄ±sÄ±, nÃ¶ron sayÄ±sÄ±, aktivasyon fonksiyonu, optimizer tipi, Ã¶ÄŸrenme oranÄ±, L2 ve dropout oranlarÄ± gibi birÃ§ok hiperparametre iÃ§in bir arama uzayÄ± tanÄ±mlanmÄ±ÅŸtÄ±r.

RandomSearch Stratejisi: TanÄ±mlanan uzayda rastgele kombinasyonlar deneyerek en iyi performansÄ± (val_loss) veren modeli bulmuÅŸtur.

ğŸ–¼ï¸ EvriÅŸimli Sinir AÄŸlarÄ± (CNN) ile GÃ¶rÃ¼ntÃ¼ SÄ±nÄ±flandÄ±rma

Bilgisayarla GÃ¶rÃ¼ (Computer Vision) alanÄ±nÄ±n temelini oluÅŸturan EvriÅŸimli Sinir AÄŸlarÄ± (CNN), CIFAR-10 veri seti Ã¼zerinde Ã§ok sÄ±nÄ±flÄ± gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma gÃ¶revi iÃ§in uygulanmÄ±ÅŸtÄ±r.

Mimari BileÅŸenleri:

Conv2D: GÃ¶rÃ¼ntÃ¼lerden hiyerarÅŸik Ã¶zellik haritalarÄ± (kenarlar, dokular, ÅŸekiller) Ã§Ä±karmak iÃ§in kullanÄ±lÄ±r.

MaxPooling2D: Ã–zellik haritalarÄ±nÄ± alt-Ã¶rnekleyerek (downsampling) boyutsal azaltma yapar ve en belirgin Ã¶zellikleri korur.

Flatten & Dense: Ã‡Ä±karÄ±lan Ã¶zelliklerin son sÄ±nÄ±flandÄ±rma katmanlarÄ±na baÄŸlanmasÄ±nÄ± saÄŸlar.

EÄŸitim Stratejisi:

sparse_categorical_crossentropy kayÄ±p fonksiyonu, one-hot encode edilmemiÅŸ etiketler iÃ§in verimli bir ÅŸekilde kullanÄ±lmÄ±ÅŸtÄ±r.

ModelCheckpoint ile eÄŸitim sÄ±rasÄ±ndaki en iyi model kaydedilmiÅŸtir.

ğŸ“ˆ Tekrarlayan Sinir AÄŸlarÄ± (RNN) ile Zaman Serisi Tahmini

SÄ±ralÄ± veriler iÃ§in Ã¶zel olarak tasarlanmÄ±ÅŸ RNN mimarileri, elektrik tÃ¼ketim verisi Ã¼zerinde zaman serisi tahminlemesi (time series forecasting) yapmak amacÄ±yla karÅŸÄ±laÅŸtÄ±rmalÄ± olarak incelenmiÅŸtir.

Model KarÅŸÄ±laÅŸtÄ±rmasÄ±:

Simple RNN: Temel sÄ±ralÄ± baÄŸÄ±mlÄ±lÄ±klarÄ± yakalamak iÃ§in bir referans model.

LSTM (Long Short-Term Memory): Uzun vadeli baÄŸÄ±mlÄ±lÄ±klarÄ± kapÄ± mekanizmalarÄ± ile Ã¶ÄŸrenen geliÅŸmiÅŸ mimari.

GRU (Gated Recurrent Unit): LSTM'e benzer performans gÃ¶steren, daha verimli ve daha az karmaÅŸÄ±k bir mimari.

Teknik Pipeline:

Pencereleme (Windowing): Zaman serisi verisi, denetimli Ã¶ÄŸrenme formatÄ±na (girdi dizileri ve hedef deÄŸerler) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r.

Tersine Ã–lÃ§eklendirme (Inverse Scaling): Model tahminleri, MAE ve RMSE gibi anlamlÄ± metriklerle deÄŸerlendirilmeden Ã¶nce orijinal Ã¶lÃ§eÄŸe geri getirilmiÅŸtir.

ğŸš€ Transfer Ã–ÄŸrenme ve Ä°nce Ayar (Transfer Learning & Fine-Tuning)

Derin Ã¶ÄŸrenmedeki en gÃ¼Ã§lÃ¼ tekniklerden biri olan Transfer Ã–ÄŸrenme, bÃ¼yÃ¼k veri setleri (ImageNet) Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸ MobileNetV2 modeli kullanÄ±larak "kediler ve kÃ¶pekler" sÄ±nÄ±flandÄ±rma problemi iÃ§in uygulanmÄ±ÅŸtÄ±r.

Ä°ki AÅŸamalÄ± EÄŸitim Stratejisi:

Ã–zellik Ã‡Ä±karÄ±mÄ± (Feature Extraction): Ã–nceden eÄŸitilmiÅŸ modelin evriÅŸimsel katmanlarÄ± dondurulmuÅŸ ve sadece yeni eklenen sÄ±nÄ±flandÄ±rma katmanlarÄ± eÄŸitilmiÅŸtir.

Ä°nce Ayar (Fine-Tuning): Temel modelin Ã¼st katmanlarÄ± Ã§Ã¶zÃ¼lmÃ¼ÅŸ ve tÃ¼m model, daha dÃ¼ÅŸÃ¼k bir Ã¶ÄŸrenme oranÄ± ile yeniden eÄŸitilerek Ã¶nceden Ã¶ÄŸrenilmiÅŸ Ã¶zelliklerin yeni gÃ¶reve adapte olmasÄ± saÄŸlanmÄ±ÅŸtÄ±r.

ğŸ”§ Veri Ã–n Ä°ÅŸleme ve Pipeline En Ä°yi Pratikleri

TÃ¼m projelerde, model performansÄ±nÄ± doÄŸrudan etkileyen tutarlÄ± ve modern veri hazÄ±rlama teknikleri kullanÄ±lmÄ±ÅŸtÄ±r:

Temel Ã–n Ä°ÅŸleme AdÄ±mlarÄ±:

Ã–lÃ§eklendirme (Scaling): StandardScaler ve MinMaxScaler ile Ã¶zelliklerin belirli bir aralÄ±ÄŸa getirilmesi ve veri sÄ±zÄ±ntÄ±sÄ±nÄ±n Ã¶nlenmesi.

Zaman OdaklÄ± BÃ¶lÃ¼mleme (Time-based Splitting): Zaman serisi verilerinde zamansal bÃ¼tÃ¼nlÃ¼ÄŸÃ¼n korunmasÄ±.

TensorFlow Veri Pipeline'Ä± (tf.data):

BÃ¼yÃ¼k veri setlerinde verimli eÄŸitim iÃ§in .shuffle(), .batch() ve .prefetch() metodlarÄ±nÄ±n etkin kullanÄ±mÄ±.

ğŸ¯ Performans DeÄŸerlendirme ve Metrikler

FarklÄ± problem tipleri iÃ§in doÄŸru deÄŸerlendirme metrikleri seÃ§ilmiÅŸtir:

SÄ±nÄ±flandÄ±rma Metrikleri: Accuracy, Loss, Precision, Recall, Confusion Matrix.

Tahminleme (Forecasting) Metrikleri: MAE (Ortalama Mutlak Hata), RMSE (KÃ¶k Ortalama Kare Hata).

Analiz AraÃ§larÄ±: EÄŸitim/Validasyon kayÄ±p ve baÅŸarÄ±m eÄŸrilerinin Matplotlib ile gÃ¶rselleÅŸtirilerek aÅŸÄ±rÄ± Ã¶ÄŸrenme gibi problemlerin teÅŸhis edilmesi.

ğŸ“ Key Learnings ve Gelecek YÃ¶nelimler

Bu eÄŸitim serisi, farklÄ± derin Ã¶ÄŸrenme mimarilerinin ne zaman ve nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± pratik olarak gÃ¶stermiÅŸtir. Gelecek adÄ±mlar iÃ§in aÅŸaÄŸÄ±daki ileri seviye konularÄ±n incelenmesi Ã¶nerilmektedir:

Transformer Mimarileri ve Attention MekanizmasÄ±

Ãœretken Modeller (GANs, VAEs, Diffusion Models)

PekiÅŸtirmeli Ã–ÄŸrenme (Reinforcement Learning)

Modellerin Ãœretime AlÄ±nmasÄ± (Deployment with TF Serving, ONNX)
